{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KMubAwwP04G"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-XZm7sajbmM",
        "outputId": "6e63480e-92c8-4480-ec35-b4308c59bd0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting blosum\n",
            "  Downloading blosum-2.0.2-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: blosum\n",
            "Successfully installed blosum-2.0.2\n",
            "Collecting Bio\n",
            "  Downloading bio-1.5.9-py3-none-any.whl (276 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.4/276.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting biopython>=1.80 (from Bio)\n",
            "  Downloading biopython-1.81-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from Bio) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from Bio) (4.66.1)\n",
            "Collecting mygene (from Bio)\n",
            "  Downloading mygene-3.2.2-py2.py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from Bio) (1.5.3)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.10/dist-packages (from Bio) (1.7.0)\n",
            "Collecting gprofiler-official (from Bio)\n",
            "  Downloading gprofiler_official-1.0.0-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython>=1.80->Bio) (1.23.5)\n",
            "Collecting biothings-client>=0.2.6 (from mygene->Bio)\n",
            "  Downloading biothings_client-0.3.0-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->Bio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->Bio) (2023.3)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch->Bio) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch->Bio) (23.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->Bio) (2023.7.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->Bio) (1.16.0)\n",
            "Installing collected packages: biopython, gprofiler-official, biothings-client, mygene, Bio\n",
            "Successfully installed Bio-1.5.9 biopython-1.81 biothings-client-0.3.0 gprofiler-official-1.0.0 mygene-3.2.2\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.22.0-py3-none-any.whl (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, huggingface-hub, transformers, accelerate\n",
            "Successfully installed accelerate-0.22.0 huggingface-hub-0.16.4 safetensors-0.3.3 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.32.1\n",
            "Collecting protein-bert\n",
            "  Downloading protein_bert-1.0.1-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from protein-bert) (2.12.0)\n",
            "Collecting tensorflow-addons (from protein-bert)\n",
            "  Downloading tensorflow_addons-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.1/612.1 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from protein-bert) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from protein-bert) (1.5.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from protein-bert) (3.9.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from protein-bert) (4.9.3)\n",
            "Collecting pyfaidx (from protein-bert)\n",
            "  Downloading pyfaidx-0.7.2.1-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->protein-bert) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->protein-bert) (2023.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pyfaidx->protein-bert) (1.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pyfaidx->protein-bert) (67.7.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->protein-bert) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->protein-bert) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->protein-bert) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->protein-bert) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->protein-bert) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->protein-bert) (1.57.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow->protein-bert) (0.4.14)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->protein-bert) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->protein-bert) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->protein-bert) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->protein-bert) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->protein-bert) (3.20.3)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow->protein-bert) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->protein-bert) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->protein-bert) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->protein-bert) (4.7.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->protein-bert) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->protein-bert) (0.33.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->protein-bert)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->protein-bert) (0.41.2)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow->protein-bert) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow->protein-bert) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->protein-bert) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->protein-bert) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->protein-bert) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->protein-bert) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->protein-bert) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->protein-bert) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->protein-bert) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->protein-bert) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->protein-bert) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->protein-bert) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->protein-bert) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->protein-bert) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->protein-bert) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->protein-bert) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow->protein-bert) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->protein-bert) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->protein-bert) (3.2.2)\n",
            "Installing collected packages: typeguard, pyfaidx, tensorflow-addons, protein-bert\n",
            "Successfully installed protein-bert-1.0.1 pyfaidx-0.7.2.1 tensorflow-addons-0.21.0 typeguard-2.13.3\n",
            "Requirement already satisfied: biopython in /usr/local/lib/python3.10/dist-packages (1.81)\n",
            "Collecting biotite\n",
            "  Downloading biotite-0.37.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.23.5)\n",
            "Requirement already satisfied: requests>=2.12 in /usr/local/lib/python3.10/dist-packages (from biotite) (2.31.0)\n",
            "Requirement already satisfied: msgpack>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from biotite) (1.0.5)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/dist-packages (from biotite) (3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.12->biotite) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.12->biotite) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.12->biotite) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.12->biotite) (2023.7.22)\n",
            "Installing collected packages: biotite\n",
            "Successfully installed biotite-0.37.0\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.32.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.22.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting fair-esm\n",
            "  Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fair-esm\n",
            "Successfully installed fair-esm-2.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install blosum\n",
        "!pip install Bio\n",
        "!pip3 install torch torchvision torchaudio transformers sentencepiece accelerate --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "!pip install protein-bert\n",
        "!pip install biopython biotite\n",
        "!pip3 install torch torchvision torchaudio transformers sentencepiece accelerate --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "!pip install fair-esm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3BStrXj6JQ2",
        "outputId": "e73032e6-566a-40fd-aecc-db6ddac3d577"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import t\n",
        "import blosum as bl\n",
        "from Bio import SeqIO\n",
        "import random\n",
        "from scipy import stats\n",
        "import torch\n",
        "import esm\n",
        "import re\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "import re\n",
        "import random\n",
        "import pickle\n",
        "import statistics\n",
        "\n",
        "from transformers import T5Tokenizer, T5EncoderModel\n",
        "from transformers import AlbertModel, AlbertTokenizer\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from transformers import XLNetModel, XLNetTokenizer\n",
        "import time\n",
        "from zipfile import ZipFile\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device: {}\".format(device))\n",
        "\n",
        "torch.set_grad_enabled(False)\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq9u86RyHKk_"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTuu_8jcuDq_"
      },
      "source": [
        "## T5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7VGs9HFct_B9"
      },
      "outputs": [],
      "source": [
        "def ProtT5_initialize():\n",
        "\n",
        "  print(\"ProtT5 Initialize : \")\n",
        "  transformer_link = \"Rostlab/prot_t5_xl_half_uniref50-enc\"\n",
        "  print(\"Loading: {}\".format(transformer_link))\n",
        "  T5 = T5EncoderModel.from_pretrained(transformer_link)\n",
        "  T5.full() if device=='cpu' else T5.half() # only cast to full-precision if no GPU is available\n",
        "  T5 = T5.to(device)\n",
        "  T5 = T5.eval()\n",
        "  T5_tokenizer = T5Tokenizer.from_pretrained(transformer_link, do_lower_case=False)\n",
        "\n",
        "  return T5 , T5_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HFSxYPYZuCs1"
      },
      "outputs": [],
      "source": [
        "def get_embs_T5(T5, tokenizer, sequences, n):\n",
        "  sequence_examples = sequences[:n]\n",
        "\n",
        "  # this will replace all rare/ambiguous amino acids by X and introduce white-space between all amino acids\n",
        "  sequence_examples = [\" \".join(list(re.sub(r\"[UZOB]\", \"X\", sequence))) for sequence in sequence_examples]\n",
        "\n",
        "  # tokenize sequences and pad up to the longest sequence in the batch\n",
        "  ids = tokenizer.batch_encode_plus(sequence_examples, add_special_tokens=True, padding= True)\n",
        "  input_ids = torch.tensor(ids['input_ids']).to(device)\n",
        "  attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
        "\n",
        "  # generate embeddings\n",
        "  with torch.no_grad():\n",
        "      embedding_repr = T5(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "  last_layer_repr = embedding_repr.last_hidden_state\n",
        "  final_embs = []\n",
        "  for i in range(len(last_layer_repr)):\n",
        "    final_embs.append(last_layer_repr[i , :len(sequences[i])])\n",
        "\n",
        "  return final_embs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtP4O4na_FAe"
      },
      "source": [
        "## ESM1b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "r6o9K45CGpxw"
      },
      "outputs": [],
      "source": [
        "def ESM1b_initialize():\n",
        "  # Load ESM-1b model\n",
        "  print(\"ESM1b Initialize : \")\n",
        "  ESM1b, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()\n",
        "  batch_converter = alphabet.get_batch_converter()\n",
        "  ESM1b.eval()  # disables dropout for deterministic results\n",
        "\n",
        "  return ESM1b, batch_converter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5VYaYR2lGuRj"
      },
      "outputs": [],
      "source": [
        "def get_embs_ESM1b(ESM1b, batch_converter, sequences, n):\n",
        "  sequences = sequences[:n]\n",
        "  data = [(\"\" , sequences[0])]\n",
        "\n",
        "  batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
        "\n",
        "  # Extract per-residue representations\n",
        "  with torch.no_grad():\n",
        "      results = ESM1b(batch_tokens, repr_layers=[33], return_contacts= False)\n",
        "  token_representations = results[\"representations\"][33]\n",
        "\n",
        "  final_embs = []\n",
        "  for i in range(len(token_representations)):\n",
        "    final_embs.append(token_representations[i][1:-1])\n",
        "\n",
        "  return final_embs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4f4hYnn_J-Y"
      },
      "source": [
        "## ESM2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0-hKY_uJ_RQK"
      },
      "outputs": [],
      "source": [
        "def ESM2_initialize():\n",
        "  # Load ESM-2 model\n",
        "  print(\"ESM2 Initialize : \")\n",
        "  ESM2, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
        "  batch_converter = alphabet.get_batch_converter()\n",
        "  ESM2.eval()  # disables dropout for deterministic results\n",
        "\n",
        "  return ESM2, batch_converter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3uy6XUL_BgXP"
      },
      "outputs": [],
      "source": [
        "def get_embs_ESM2(ESM2, batch_converter, sequences, n):\n",
        "  sequences = sequences[:n]\n",
        "  data = [(\"\" , sequences[0])]\n",
        "\n",
        "  batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
        "\n",
        "  # Extract per-residue representations\n",
        "  with torch.no_grad():\n",
        "      results = ESM2(batch_tokens, repr_layers=[33], return_contacts= False)\n",
        "  token_representations = results[\"representations\"][33]\n",
        "\n",
        "  final_embs = []\n",
        "  for i in range(len(token_representations)):\n",
        "    final_embs.append(token_representations[i][1:-1])\n",
        "\n",
        "  return final_embs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0xNnG7IFLuU"
      },
      "source": [
        "## Bert Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yIOMmp3nFR66"
      },
      "outputs": [],
      "source": [
        "def ProtBert_initialize():\n",
        "\n",
        "  print(\"ProtBert Initialize : \")\n",
        "\n",
        "  Bert_tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
        "  Bert = BertModel.from_pretrained(\"Rostlab/prot_bert\")\n",
        "\n",
        "  Albert = Bert.to(device)\n",
        "  Albert = Bert.eval()\n",
        "\n",
        "  return Bert, Bert_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yzg4i4vqFSb6"
      },
      "outputs": [],
      "source": [
        "def get_embs_ProtBert(Bert , tokenizer , sequences , n):\n",
        "  sequence_examples = sequences[:n]\n",
        "\n",
        "  # this will replace all rare/ambiguous amino acids by X and introduce white-space between all amino acids\n",
        "  sequence_examples = [\" \".join(list(re.sub(r\"[UZOB]\", \"X\", sequence))) for sequence in sequence_examples]\n",
        "\n",
        "  ids = tokenizer.batch_encode_plus(sequence_examples, add_special_tokens=True, pad_to_max_length=True)\n",
        "  input_ids = torch.tensor(ids['input_ids']).to(device)\n",
        "  attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    embedding = Bert(input_ids=input_ids,attention_mask=attention_mask)[0]\n",
        "\n",
        "  final_embs = []\n",
        "  for seq_num in range(len(embedding)):\n",
        "      seq_len = (attention_mask[seq_num] == 1).sum()\n",
        "      seq_emd = embedding[seq_num][1:seq_len-1]\n",
        "      final_embs.append(seq_emd)\n",
        "\n",
        "  return final_embs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LCdgRFBFWW6"
      },
      "source": [
        "## Albert Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tQE-EIVnGRNP"
      },
      "outputs": [],
      "source": [
        "def ProtAlbert_initialize():\n",
        "\n",
        "  print(\"ProtAlbert Initialize : \")\n",
        "\n",
        "  Albert_tokenizer = AlbertTokenizer.from_pretrained(\"Rostlab/prot_albert\", do_lower_case=False)\n",
        "  Albert = AlbertModel.from_pretrained(\"Rostlab/prot_albert\")\n",
        "\n",
        "  Albert = Albert.to(device)\n",
        "  Albert = Albert.eval()\n",
        "\n",
        "  return Albert, Albert_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QKjAfFMBGKQq"
      },
      "outputs": [],
      "source": [
        "def get_embs_ProtAlbert(Albert, Albert_tokenizer, sequences, n):\n",
        "\n",
        "  sequences = [\" \".join(re.sub(r\"[UZOB]\", \"X\", sequence)) for sequence in sequences]\n",
        "  ids = Albert_tokenizer.batch_encode_plus(sequences, add_special_tokens=True, padding = 'longest')\n",
        "  input_ids = torch.tensor(ids['input_ids']).to(device)\n",
        "  attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      embedding = Albert(input_ids = input_ids , attention_mask = attention_mask)[0]\n",
        "\n",
        "  features = []\n",
        "  for seq_num in range(len(embedding)):\n",
        "      seq_len = (attention_mask[seq_num] == 1).sum()\n",
        "      seq_emd = embedding[seq_num][1 : seq_len - 1]\n",
        "      features.append(seq_emd)\n",
        "\n",
        "  return features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ctdjBhTGi9z"
      },
      "source": [
        "## XLNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_M2uk9EsGn00"
      },
      "outputs": [],
      "source": [
        "def XLNet_initialize():\n",
        "\n",
        "  print(\"XLNet Initialize : \")\n",
        "\n",
        "  XLNet_tokenizer = XLNetTokenizer.from_pretrained(\"Rostlab/prot_xlnet\" , do_lower_case=False)\n",
        "  XLNet = XLNetModel.from_pretrained(\"Rostlab/prot_xlnet\" , mem_len= 1024)\n",
        "\n",
        "  XLNet = XLNet.to(device)\n",
        "  XLNet = XLNet.eval()\n",
        "\n",
        "  return XLNet, XLNet_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bcwC7KpxGrCr"
      },
      "outputs": [],
      "source": [
        "def get_embs_XLNet(XLNet, XLNet_tokenizer, sequences, n):\n",
        "\n",
        "  sequences = [\" \".join(re.sub(r\"[UZOBX]\" , \"<unk>\", sequence)) for sequence in sequences]\n",
        "  ids = XLNet_tokenizer.batch_encode_plus(sequences, add_special_tokens = True, padding = 'longest')\n",
        "  input_ids = torch.tensor(ids['input_ids']).to(device)\n",
        "  attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      output = XLNet(input_ids = input_ids , attention_mask = attention_mask)\n",
        "      embedding = output.last_hidden_state\n",
        "\n",
        "  features = []\n",
        "  for seq_num in range(len(embedding)):\n",
        "      seq_len = (attention_mask[seq_num] == 1).sum()\n",
        "      padded_seq_len = len(attention_mask[seq_num])\n",
        "      seq_emd = embedding[seq_num][padded_seq_len - seq_len : padded_seq_len - 2]\n",
        "      features.append(seq_emd)\n",
        "\n",
        "\n",
        "  return features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qs6JenWnHYHo"
      },
      "source": [
        "# Alignment Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTFhk7slsYA1"
      },
      "source": [
        "## Global"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "r5iNmd9o6Q3V"
      },
      "outputs": [],
      "source": [
        "def affine_global_dp(seq_1, seq_2, g_open, g_ext,\n",
        "                     scoring=\"ProtT5\", Model=None, Model_tokenizer=None):\n",
        "\n",
        "    MODELS_LIST = [\"ProtT5\", \"ProtBert\", \"ProtAlbert\", \"XLNet\", \"ESM1b\", \"ESM2\"]\n",
        "\n",
        "    # initialize the matrix\n",
        "    m = len(seq_1);\n",
        "    n = len(seq_2)\n",
        "    M = np.zeros([m + 1, n + 1])\n",
        "    M[0, 1:] = g_open + g_ext * np.arange(0, n, 1)\n",
        "    M[1:, 0] = g_open + g_ext * np.arange(0, m, 1)\n",
        "    L = np.copy(M);\n",
        "    U = np.copy(M)\n",
        "    L[1:, 0] = L[1:, 0] + g_open;\n",
        "    U[0, 1:] = U[0, 1:] + g_open  # avoiding Gotoh's error\n",
        "\n",
        "    # fill up\n",
        "    tracer = np.zeros([np.shape(M)[0], np.shape(M)[1], 7])\n",
        "\n",
        "    if scoring == \"ProtT5\":\n",
        "        emb1 = get_embs_T5(Model, Model_tokenizer, [seq_1], 1)[0].cpu().numpy()\n",
        "        emb2 = get_embs_T5(Model, Model_tokenizer, [seq_2], 1)[0].cpu().numpy()\n",
        "        cos = torch.nn.CosineSimilarity(dim=0)\n",
        "\n",
        "    if scoring == \"ProtBert\":\n",
        "        emb1 = get_embs_ProtBert(Model, Model_tokenizer, [seq_1], 1)[0].cpu().numpy()\n",
        "        emb2 = get_embs_ProtBert(Model, Model_tokenizer, [seq_2], 1)[0].cpu().numpy()\n",
        "        cos = torch.nn.CosineSimilarity(dim=0)\n",
        "\n",
        "    if scoring == \"ProtAlbert\":\n",
        "        emb1 = get_embs_ProtAlbert(Model, Model_tokenizer, [seq_1], 1)[0].cpu().numpy()\n",
        "        emb2 = get_embs_ProtAlbert(Model, Model_tokenizer, [seq_2], 1)[0].cpu().numpy()\n",
        "        cos = torch.nn.CosineSimilarity(dim=0)\n",
        "\n",
        "    if scoring == \"ProtXLNet\":\n",
        "        emb1 = get_embs_XLNet(Model, Model_tokenizer, [seq_1], 1)[0].cpu().numpy()\n",
        "        emb2 = get_embs_XLNet(Model, Model_tokenizer, [seq_2], 1)[0].cpu().numpy()\n",
        "        cos = torch.nn.CosineSimilarity(dim=0)\n",
        "\n",
        "    if scoring == \"ESM1b\":\n",
        "        emb1 = get_embs_ESM1b(Model, Model_tokenizer, [seq_1], 1)[0].cpu().numpy()\n",
        "        emb2 = get_embs_ESM1b(Model, Model_tokenizer, [seq_2], 1)[0].cpu().numpy()\n",
        "        cos = torch.nn.CosineSimilarity(dim=0)\n",
        "\n",
        "    if scoring == \"ESM2\":\n",
        "        emb1 = get_embs_ESM2(Model, Model_tokenizer, [seq_1], 1)[0].cpu().numpy()\n",
        "        emb2 = get_embs_ESM2(Model, Model_tokenizer, [seq_2], 1)[0].cpu().numpy()\n",
        "        cos = torch.nn.CosineSimilarity(dim=0)\n",
        "\n",
        "    for i in range(1, m + 1):\n",
        "        for j in range(1, n + 1):\n",
        "            l_arr = np.array([M[i, j - 1] + g_open, L[i, j - 1] + g_ext])\n",
        "            L[i, j] = np.max(l_arr)\n",
        "            l_where = l_arr == np.max(l_arr)\n",
        "\n",
        "            u_arr = np.array([M[i - 1, j] + g_open, U[i - 1, j] + g_ext])\n",
        "            U[i, j] = np.max(u_arr)\n",
        "            u_where = u_arr == np.max(u_arr)\n",
        "\n",
        "            if scoring in MODELS_LIST:\n",
        "                sim = cos(torch.tensor(emb1[i - 1], dtype=torch.float32)\n",
        "                          , torch.tensor(emb2[j - 1], dtype=torch.float32)).item()\n",
        "\n",
        "                m_arr = np.array([M[i - 1, j - 1] + sim, U[i, j], L[i, j]])\n",
        "\n",
        "            M[i, j] = np.max(m_arr)\n",
        "            m_where = m_arr == np.max(m_arr)\n",
        "\n",
        "            idx = np.hstack([m_where, u_where, l_where])\n",
        "            tracer[i, j, idx] = 1\n",
        "\n",
        "    # traceback\n",
        "\n",
        "    alignment = []\n",
        "    alignment.append(traceback_g(tracer, seq_1, seq_2, affine= True, roadmap=0))\n",
        "\n",
        "    alignment = list(set(map(tuple, alignment)))\n",
        "\n",
        "    return M, L, U, tracer, alignment\n",
        "\n",
        "\n",
        "def traceback_g(tracer, seq_1, seq_2, mat=None, affine=False, roadmap=0):\n",
        "    # get sequence lengths\n",
        "    m = len(seq_1);\n",
        "    n = len(seq_2)\n",
        "\n",
        "    # convert to numpy arrays\n",
        "    x = np.array(list(seq_1), dtype='object')\n",
        "    y = np.array(list(seq_2), dtype='object')\n",
        "\n",
        "    # set start location\n",
        "    st = [m + 1, n + 1]\n",
        "\n",
        "    st_lv = 0  # start in midgard\n",
        "\n",
        "    while ((st[0] > 1) & (st[1] > 1)):\n",
        "\n",
        "        B = np.zeros([2, 2])  # define 2x2 box which specifies which way to move\n",
        "\n",
        "        if affine is True:\n",
        "            Tr = np.zeros([7])  # define a 7x1 Tr array (will store arrows at each step)\n",
        "        else:\n",
        "            Tr = np.zeros([3])  # define a 3x1 Tr array (will store arrows at each step)\n",
        "\n",
        "        if affine is False:\n",
        "            Tr[0] = np.copy(tracer[st[0] - 1, st[1] - 1, 0])\n",
        "            Tr[1] = np.copy(tracer[st[0] - 1, st[1] - 1, 1])\n",
        "            Tr[2] = np.copy(tracer[st[0] - 1, st[1] - 1, 2])\n",
        "\n",
        "        else:\n",
        "            # tracer\n",
        "            Tr[0] = np.copy(tracer[st[0] - 1, st[1] - 1, 0])\n",
        "            Tr[1] = np.copy(tracer[st[0] - 1, st[1] - 1, 1])\n",
        "            Tr[2] = np.copy(tracer[st[0] - 1, st[1] - 1, 2])\n",
        "            Tr[3] = np.copy(tracer[st[0] - 1, st[1] - 1, 3])\n",
        "            Tr[4] = np.copy(tracer[st[0] - 1, st[1] - 1, 4])\n",
        "            Tr[5] = np.copy(tracer[st[0] - 1, st[1] - 1, 5])\n",
        "            Tr[6] = np.copy(tracer[st[0] - 1, st[1] - 1, 6])\n",
        "\n",
        "        # bifurcations\n",
        "        if affine is True:\n",
        "            levels = [[2, 0, 1], [4, 3], [6, 5]]\n",
        "        else:\n",
        "            levels = [[2, 0, 1]]\n",
        "        for l in levels:\n",
        "            if np.sum(Tr[l]) > 1:\n",
        "                choose = np.where(Tr[l] == 1)[0]\n",
        "                Tr[l] = 0\n",
        "                if roadmap == 0:\n",
        "                    r = np.random.choice(choose, 1)[0]  # random turning\n",
        "                elif roadmap == 1:\n",
        "                    r = choose[-1]  # highroad\n",
        "                elif roadmap == 2:\n",
        "                    r = choose[0]  # lowroad\n",
        "                else:\n",
        "                    raise Exception(\"roadmap only accepts 0: random turning, 1: highroad, 2: lowroad\")\n",
        "                Tr[l[r]] = 1\n",
        "\n",
        "        # level up-down\n",
        "        if ((Tr[0] == 1) & (st_lv == 0)):  # diagonal\n",
        "            B[0, 0] = 1\n",
        "\n",
        "        if ((Tr[1] == 1) & (st_lv == 0)):\n",
        "            if affine is True:\n",
        "                st_lv = 1  # level up\n",
        "            else:\n",
        "                B[0, 1] = 1\n",
        "\n",
        "        if ((Tr[2] == 1) & (st_lv == 0)):\n",
        "            if affine is True:\n",
        "                st_lv = 2  # level down\n",
        "            else:\n",
        "                B[1, 0] = 1\n",
        "\n",
        "        # affine gaps allow for level shifts\n",
        "        if affine is True:\n",
        "            if ((Tr[4] == 1) & (st_lv == 1)):  # move up\n",
        "                B[0, 1] = 1\n",
        "\n",
        "            if ((Tr[3] == 1) & (st_lv == 1)):  # move up back to main\n",
        "                st_lv = 0\n",
        "                B[0, 1] = 1\n",
        "\n",
        "            if ((Tr[6] == 1) & (st_lv == 2)):  # move left\n",
        "                B[1, 0] = 1\n",
        "\n",
        "            if ((Tr[5] == 1) & (st_lv == 2)):  # move left back to main\n",
        "                st_lv = 0\n",
        "                B[1, 0] = 1\n",
        "\n",
        "        # movements\n",
        "        if B[0, 1] == 1:  # upward\n",
        "            y = np.insert(y, st[1] - 1, '-')  # add a gap\n",
        "            st[0] = st[0] - 1\n",
        "\n",
        "        if B[1, 0] == 1:  # leftward\n",
        "            x = np.insert(x, st[0] - 1, '-')  # add a gap\n",
        "            st[1] = st[1] - 1\n",
        "\n",
        "        if B[0, 0] == 1:  # diagonal\n",
        "            st[1] = st[1] - 1\n",
        "            st[0] = st[0] - 1\n",
        "\n",
        "    # some end gaps are left when you hit the upper/lower end of the matrix or a 0\n",
        "    end_size = (np.size(x) - np.size(y))  # how many gaps and for which sequence\n",
        "    end_gap = (['-'] * abs(end_size))\n",
        "    if end_size > 0:\n",
        "        y = np.insert(y, 0, end_gap)\n",
        "    elif end_size < 0:\n",
        "        x = np.insert(x, 0, end_gap)\n",
        "\n",
        "    # check no overlapping gaps\n",
        "    x = np.where(((x == '-') & (y == '-')), None, x)\n",
        "    y = np.where((x == None), '', y)\n",
        "    x = np.where((x == None), '', x)\n",
        "\n",
        "    return np.sum(x), np.sum(y)\n",
        "\n",
        "\n",
        "def traceback_iterator_g(tracer, seq_1, seq_2,\n",
        "                         affine=False):\n",
        "    alignment = []\n",
        "    alignment.append(traceback_g(tracer, seq_1, seq_2, affine=affine, roadmap=0))\n",
        "\n",
        "    return list(set(map(tuple, alignment)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiNZQ2SQJM54"
      },
      "source": [
        "## Prefix/Suffix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MqzYFa7dJTY9"
      },
      "outputs": [],
      "source": [
        "def affine_semi_global_dp(seq_1, seq_2, g_open, g_ext,\n",
        "                          high_low=False, scoring=\"ProtT5\", Model=None, Model_tokenizer=None):\n",
        "    MODELS_LIST = [\"ProtT5\", \"ProtBert\", \"ProtAlbert\", \"ProtXLNet\", \"ESM1b\", \"ESM2\"]\n",
        "\n",
        "    # initialize the matrix\n",
        "    m = len(seq_1);\n",
        "    n = len(seq_2)\n",
        "    M = np.zeros([m + 1, n + 1])\n",
        "    M[0, 1:] = 0\n",
        "    M[1:, 0] = 0\n",
        "    L = np.copy(M);\n",
        "    U = np.copy(M)\n",
        "    L[1:, 0] = 0;\n",
        "    U[0, 1:] = 0\n",
        "\n",
        "    # fill up\n",
        "    tracer = np.zeros([np.shape(M)[0], np.shape(M)[1], 7])\n",
        "\n",
        "    if scoring == \"ProtT5\":\n",
        "        emb1 = get_embs_T5(Model, Model_tokenizer, [seq_1], 1)[0].cpu().numpy()\n",
        "        emb2 = get_embs_T5(Model, Model_tokenizer, [seq_2], 1)[0].cpu().numpy()\n",
        "        cos = torch.nn.CosineSimilarity(dim=0)\n",
        "\n",
        "    if scoring == \"ProtBert\":\n",
        "        emb1 = get_embs_ProtBert(Model, Model_tokenizer, [seq_1], 1)[0].cpu().numpy()\n",
        "        emb2 = get_embs_ProtBert(Model, Model_tokenizer, [seq_2], 1)[0].cpu().numpy()\n",
        "        cos = torch.nn.CosineSimilarity(dim=0)\n",
        "\n",
        "    if scoring == \"ProtAlbert\":\n",
        "        emb1 = get_embs_ProtAlbert(Model, Model_tokenizer, [seq_1], 1)[0].cpu().numpy()\n",
        "        emb2 = get_embs_ProtAlbert(Model, Model_tokenizer, [seq_2], 1)[0].cpu().numpy()\n",
        "        cos = torch.nn.CosineSimilarity(dim=0)\n",
        "\n",
        "    if scoring == \"ProtXLNet\":\n",
        "        emb1 = get_embs_XLNet(Model, Model_tokenizer, [seq_1], 1)[0].cpu().numpy()\n",
        "        emb2 = get_embs_XLNet(Model, Model_tokenizer, [seq_2], 1)[0].cpu().numpy()\n",
        "        cos = torch.nn.CosineSimilarity(dim=0)\n",
        "\n",
        "    if scoring == \"ESM1b\":\n",
        "        emb1 = get_embs_ESM1b(Model, Model_tokenizer, [seq_1], 1)[0].cpu().numpy()\n",
        "        emb2 = get_embs_ESM1b(Model, Model_tokenizer, [seq_2], 1)[0].cpu().numpy()\n",
        "        cos = torch.nn.CosineSimilarity(dim=0)\n",
        "\n",
        "    if scoring == \"ESM2\":\n",
        "        emb1 = get_embs_ESM2(Model, Model_tokenizer, [seq_1], 1)[0].cpu().numpy()\n",
        "        emb2 = get_embs_ESM2(Model, Model_tokenizer, [seq_2], 1)[0].cpu().numpy()\n",
        "        cos = torch.nn.CosineSimilarity(dim=0)\n",
        "\n",
        "    for i in range(1, m + 1):\n",
        "        for j in range(1, n + 1):\n",
        "            l_arr = np.array([M[i, j - 1] + g_open, L[i, j - 1] + g_ext])\n",
        "            L[i, j] = np.max(l_arr)\n",
        "            l_where = l_arr == np.max(l_arr)\n",
        "\n",
        "            u_arr = np.array([M[i - 1, j] + g_open, U[i - 1, j] + g_ext])\n",
        "            U[i, j] = np.max(u_arr)\n",
        "            u_where = u_arr == np.max(u_arr)\n",
        "\n",
        "            if scoring in MODELS_LIST:\n",
        "                sim = cos(torch.tensor(emb1[i - 1], dtype=torch.float32)\n",
        "                          , torch.tensor(emb2[j - 1], dtype=torch.float32)).item()\n",
        "\n",
        "                m_arr = np.array([M[i - 1, j - 1] + sim, U[i, j], L[i, j]])\n",
        "\n",
        "            M[i, j] = np.max(m_arr)\n",
        "            m_where = m_arr == np.max(m_arr)\n",
        "\n",
        "            idx = np.hstack([m_where, u_where, l_where])\n",
        "            tracer[i, j, idx] = 1\n",
        "\n",
        "\n",
        "    alignment = []\n",
        "    alignment.append(traceback_sg(tracer, seq_1, seq_2, mat=M, affine=True,\n",
        "                                  local= True, roadmap=0))\n",
        "    alignment = list(set(map(tuple, alignment)))\n",
        "\n",
        "    return M, L, U, tracer, alignment\n",
        "\n",
        "\n",
        "def traceback_sg(tracer, seq_1, seq_2, mat=None, local=False, affine=False, roadmap=0):\n",
        "\n",
        "    m = len(seq_1);\n",
        "    n = len(seq_2)\n",
        "\n",
        "    x = np.array(list(seq_1), dtype='object')\n",
        "    y = np.array(list(seq_2), dtype='object')\n",
        "\n",
        "    # set start location\n",
        "    if roadmap == 0:\n",
        "        r = np.random.choice(range(np.size(np.where(mat == np.max(mat))[0])), 1)[0]  # random maxima\n",
        "    elif roadmap == 1:\n",
        "        r = -1\n",
        "    elif roadmap == 2:\n",
        "        r = 0\n",
        "\n",
        "    st = [(np.where(mat == np.max(mat))[0][r]) + 1, (np.where(mat == np.max(mat))[1][r]) + 1]\n",
        "\n",
        "    # set starting gaps based on the start location\n",
        "    start_size = ((m - st[0]) - (n - st[1]))  # how many gaps and for which sequence\n",
        "    start_gap = (['-'] * abs(start_size))\n",
        "    if start_size > 0:\n",
        "        y = np.append(y, start_gap)\n",
        "    elif start_size < 0:\n",
        "        x = np.append(x, start_gap)\n",
        "\n",
        "    st_lv = 0  # start in midgard\n",
        "\n",
        "    while ((st[0] > 1) & (st[1] > 1)):\n",
        "\n",
        "        B = np.zeros([2, 2])  # define 2x2 box which specifies which way to move\n",
        "\n",
        "        if affine is True:\n",
        "            Tr = np.zeros([7])  # define a 7x1 Tr array (will store arrows at each step)\n",
        "        else:\n",
        "            Tr = np.zeros([3])  # define a 3x1 Tr array (will store arrows at each step)\n",
        "\n",
        "\n",
        "        if affine is False:\n",
        "            Tr[0] = np.copy(tracer[st[0] - 1, st[1] - 1, 0])\n",
        "            Tr[1] = np.copy(tracer[st[0] - 1, st[1] - 1, 1])\n",
        "            Tr[2] = np.copy(tracer[st[0] - 1, st[1] - 1, 2])\n",
        "\n",
        "        else:\n",
        "            # tracer\n",
        "            Tr[0] = np.copy(tracer[st[0] - 1, st[1] - 1, 0])\n",
        "            Tr[1] = np.copy(tracer[st[0] - 1, st[1] - 1, 1])\n",
        "            Tr[2] = np.copy(tracer[st[0] - 1, st[1] - 1, 2])\n",
        "            Tr[3] = np.copy(tracer[st[0] - 1, st[1] - 1, 3])\n",
        "            Tr[4] = np.copy(tracer[st[0] - 1, st[1] - 1, 4])\n",
        "            Tr[5] = np.copy(tracer[st[0] - 1, st[1] - 1, 5])\n",
        "            Tr[6] = np.copy(tracer[st[0] - 1, st[1] - 1, 6])\n",
        "\n",
        "        # bifurcations\n",
        "        if affine is True:\n",
        "            levels = [[2, 0, 1], [4, 3], [6, 5]]\n",
        "        else:\n",
        "            levels = [[2, 0, 1]]\n",
        "        for l in levels:\n",
        "            if np.sum(Tr[l]) > 1:\n",
        "                choose = np.where(Tr[l] == 1)[0]\n",
        "                Tr[l] = 0\n",
        "                if roadmap == 0:\n",
        "                    r = np.random.choice(choose, 1)[0]  # random turning\n",
        "                elif roadmap == 1:\n",
        "                    r = choose[-1]  # highroad\n",
        "                elif roadmap == 2:\n",
        "                    r = choose[0]  # lowroad\n",
        "                else:\n",
        "                    raise Exception(\"roadmap only accepts 0: random turning, 1: highroad, 2: lowroad\")\n",
        "                Tr[l[r]] = 1\n",
        "\n",
        "        # level up-down\n",
        "        if ((Tr[0] == 1) & (st_lv == 0)):  # diagonal\n",
        "            B[0, 0] = 1\n",
        "\n",
        "        if ((Tr[1] == 1) & (st_lv == 0)):\n",
        "            if affine is True:\n",
        "                st_lv = 1  # level up\n",
        "            else:\n",
        "                B[0, 1] = 1\n",
        "\n",
        "        if ((Tr[2] == 1) & (st_lv == 0)):\n",
        "            if affine is True:\n",
        "                st_lv = 2  # level down\n",
        "            else:\n",
        "                B[1, 0] = 1\n",
        "\n",
        "        # affine gaps allow for level shifts\n",
        "        if affine is True:\n",
        "            if ((Tr[4] == 1) & (st_lv == 1)):  # move up\n",
        "                B[0, 1] = 1\n",
        "\n",
        "            if ((Tr[3] == 1) & (st_lv == 1)):  # move up back to main\n",
        "                st_lv = 0\n",
        "                B[0, 1] = 1\n",
        "\n",
        "            if ((Tr[6] == 1) & (st_lv == 2)):  # move left\n",
        "                B[1, 0] = 1\n",
        "\n",
        "            if ((Tr[5] == 1) & (st_lv == 2)):  # move left back to main\n",
        "                st_lv = 0\n",
        "                B[1, 0] = 1\n",
        "\n",
        "        if local is True:\n",
        "            if (mat[st[0] - 1, st[1] - 1] == 0):\n",
        "                break\n",
        "\n",
        "        # movements\n",
        "        if B[0, 1] == 1:  # upward\n",
        "            y = np.insert(y, st[1] - 1, '-')  # add a gap\n",
        "            st[0] = st[0] - 1\n",
        "\n",
        "        if B[1, 0] == 1:  # leftward\n",
        "            x = np.insert(x, st[0] - 1, '-')  # add a gap\n",
        "            st[1] = st[1] - 1\n",
        "\n",
        "        if B[0, 0] == 1:  # diagonal\n",
        "            st[1] = st[1] - 1\n",
        "            st[0] = st[0] - 1\n",
        "\n",
        "    # some end gaps are left when you hit the upper/lower end of the matrix or a 0\n",
        "    end_size = (np.size(x) - np.size(y))  # how many gaps and for which sequence\n",
        "    end_gap = (['-'] * abs(end_size))\n",
        "    if end_size > 0:\n",
        "        y = np.insert(y, 0, end_gap)\n",
        "    elif end_size < 0:\n",
        "        x = np.insert(x, 0, end_gap)\n",
        "\n",
        "    # check no overlapping gaps\n",
        "    x = np.where(((x == '-') & (y == '-')), None, x)\n",
        "    y = np.where((x == None), '', y)\n",
        "    x = np.where((x == None), '', x)\n",
        "\n",
        "    return np.sum(x), np.sum(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IMkkTPWsaF0"
      },
      "source": [
        "# Aux Funx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LBNOVyaN7ZT3"
      },
      "outputs": [],
      "source": [
        "def load_fasta(path):\n",
        "    fasta_sequences = SeqIO.parse(open(path),'fasta')\n",
        "    sequences = []\n",
        "\n",
        "    for fasta in fasta_sequences:\n",
        "        name, sequence = fasta.id, str(fasta.seq)\n",
        "        sequences.append((name, sequence.upper()))\n",
        "\n",
        "    return sequences\n",
        "\n",
        "def just_seqs(seqs):\n",
        "    final_seqs = []\n",
        "    for seq in seqs:\n",
        "        final_seqs.append(seq[1])\n",
        "\n",
        "    return final_seqs\n",
        "\n",
        "def aligned_to_indexed(seqs):\n",
        "  no_dash = []\n",
        "  positions = []\n",
        "  for seq in seqs:\n",
        "    no_dash.append(seq.replace(\"-\" , \"\"))\n",
        "    pos = []\n",
        "    for i , char in enumerate(seq):\n",
        "      if char != \"-\":\n",
        "        pos.append(i)\n",
        "    positions.append(pos)\n",
        "\n",
        "  return no_dash, positions\n",
        "\n",
        "def length_matcher(x , y , place = \"\"):\n",
        "  length = 5\n",
        "\n",
        "  if len(x) < length:\n",
        "    spaces = abs(len(x) - length)\n",
        "\n",
        "    if place == \"Back\":\n",
        "      x = \" \" * spaces + x\n",
        "    if place == \"Front\":\n",
        "      x = x + \" \" * spaces\n",
        "\n",
        "  if len(y) < length:\n",
        "    spaces = abs(len(y) - length)\n",
        "\n",
        "    if place == \"Back\":\n",
        "      y = \" \" * spaces + y\n",
        "    if place == \"Front\":\n",
        "      y = y + \" \" * spaces\n",
        "\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6brZ8knC9dz5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "achF78kUscys"
      },
      "source": [
        "# Alignment Computations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "DawofHCVAdVo"
      },
      "outputs": [],
      "source": [
        "def get_alignments(prot1, prot2, gap_penalty = 0, gap_extension_penalty = 0 ,\n",
        "                   scoring = \"ProtT5\" , alignment_type = \"Global-regular\" , Model = \"\" , Model_Tokenizer = \"\"):\n",
        "\n",
        "    if alignment_type == \"Global-regular\":\n",
        "      M, L, U , tracer , alignment= affine_global_dp(prot1, prot2, gap_penalty, gap_extension_penalty\n",
        "                                                    ,scoring = scoring , Model = Model, Model_tokenizer = Model_Tokenizer)\n",
        "      max_score = np.max(M)\n",
        "\n",
        "    if alignment_type == \"Global-end-gap-free\" or alignment_type == \"End-Gap-Free\":\n",
        "      M, L, U , tracer , alignment= affine_semi_global_dp(prot1, prot2, gap_penalty, gap_extension_penalty\n",
        "                                                    ,scoring = scoring , Model = Model, Model_tokenizer = Model_Tokenizer)\n",
        "\n",
        "      max_score = max(M[-1,-1],L[-1,-1],U[-1,-1])\n",
        "\n",
        "    aligned1 = alignment[0][0]\n",
        "    aligned2 = alignment[0][1]\n",
        "\n",
        "    return aligned1, aligned2, max_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5Hfj5rAk4_cg"
      },
      "outputs": [],
      "source": [
        "def get_visualization(prot1, prot2 , score , Type = \"\" , Model = \"\" , Model_Tokenizer = \"\"):\n",
        "\n",
        "  MODELS_LIST = [\"ProtT5\" , \"ProtBert\" , \"ProtAlbert\" , \"ProtXLNet\" , \"ESM1b\" , \"ESM2\"]\n",
        "  cos = torch.nn.CosineSimilarity(dim=0)\n",
        "\n",
        "  seqs = [prot1 , prot2]\n",
        "  no_dash , positions = aligned_to_indexed(seqs)\n",
        "\n",
        "  if Type == \"ProtT5\":\n",
        "    model = Model\n",
        "    tokenizer = Model_Tokenizer\n",
        "    p1_emb = get_embs_T5(model, tokenizer, [no_dash[0]] , 1)\n",
        "    p2_emb = get_embs_T5(model, tokenizer, [no_dash[1]] , 1)\n",
        "\n",
        "  if Type == \"ProtBert\":\n",
        "    model = Model\n",
        "    tokenizer = Model_Tokenizer\n",
        "    p1_emb = get_embs_ProtBert(model, tokenizer, [no_dash[0]] , 1)\n",
        "    p2_emb = get_embs_ProtBert(model, tokenizer, [no_dash[1]] , 1)\n",
        "\n",
        "  if Type == \"ProtAlbert\":\n",
        "    model = Model\n",
        "    tokenizer = Model_Tokenizer\n",
        "    p1_emb = get_embs_ProtAlbert(model, tokenizer, [no_dash[0]] , 1)\n",
        "    p2_emb = get_embs_ProtAlbert(model, tokenizer, [no_dash[1]] , 1)\n",
        "\n",
        "  if Type == \"ProtXLNet\":\n",
        "    model = Model\n",
        "    tokenizer = Model_Tokenizer\n",
        "    p1_emb = get_embs_XLNet(model, tokenizer, [no_dash[0]] , 1)\n",
        "    p2_emb = get_embs_XLNet(model, tokenizer, [no_dash[1]] , 1)\n",
        "\n",
        "  if Type == \"ESM1b\":\n",
        "    model = Model\n",
        "    tokenizer = Model_Tokenizer\n",
        "    p1_emb = get_embs_ESM1b(model, tokenizer, [no_dash[0]] , 1)\n",
        "    p2_emb = get_embs_ESM1b(model, tokenizer, [no_dash[1]] , 1)\n",
        "\n",
        "  if Type == \"ESM2\":\n",
        "    model = Model\n",
        "    tokenizer = Model_Tokenizer\n",
        "    p1_emb = get_embs_ESM2(model, tokenizer, [no_dash[0]] , 1)\n",
        "    p2_emb = get_embs_ESM2(model, tokenizer, [no_dash[1]] , 1)\n",
        "\n",
        "  p1_revived = \"\"\n",
        "  p2_revived = \"\"\n",
        "  aligned_info = \"\"\n",
        "\n",
        "  for i in range(len(prot1)):\n",
        "\n",
        "    if i in positions[0]:\n",
        "      p1_revived += prot1[i]\n",
        "    else:\n",
        "      p1_revived += \"-\"\n",
        "\n",
        "    if i in positions[1]:\n",
        "      p2_revived += prot2[i]\n",
        "    else:\n",
        "      p2_revived += \"-\"\n",
        "\n",
        "\n",
        "    if p1_revived[-1] == p2_revived[-1]:\n",
        "      aligned_info += p1_revived[-1]\n",
        "\n",
        "    elif p1_revived[-1] == \"-\" or p2_revived[-1] == \"-\":\n",
        "      aligned_info += \" \"\n",
        "\n",
        "    elif p1_revived[-1] != p2_revived[-1]:\n",
        "\n",
        "      if Type in MODELS_LIST:\n",
        "        sim = cos(torch.tensor(p1_emb[0][positions[0].index(i)] , dtype = torch.float32) ,\n",
        "                  torch.tensor(p2_emb[0][positions[1].index(i)] , dtype = torch.float32)).item()\n",
        "\n",
        "        aligned_info += \" \"\n",
        "\n",
        "  del model\n",
        "  del tokenizer\n",
        "\n",
        "  return p1_revived , aligned_info, p2_revived, score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Alignment For 2 Sequences"
      ],
      "metadata": {
        "id": "m7nB5_MdnBO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def alignment_file_TXT(saving_add, seqs_path, scoring, alignment_type,\n",
        "                      gap_penalty, gap_extension_penalty):\n",
        "\n",
        "  if scoring == \"ProtT5\":\n",
        "    Model , Model_Tokenizer = ProtT5_initialize()\n",
        "\n",
        "  if scoring == \"ProtBert\":\n",
        "    Model , Model_Tokenizer = ProtBert_initialize()\n",
        "\n",
        "  if scoring == \"ProtAlbert\":\n",
        "    Model , Model_Tokenizer = ProtAlbert_initialize()\n",
        "\n",
        "  if scoring == \"ProtXLNet\":\n",
        "    Model , Model_Tokenizer = XLNet_initialize()\n",
        "\n",
        "  if scoring == \"ESM1b\":\n",
        "    Model , Model_Tokenizer = ESM1b_initialize()\n",
        "\n",
        "  if scoring == \"ESM2\":\n",
        "    Model , Model_Tokenizer = ESM2_initialize()\n",
        "\n",
        "  seqs = load_fasta(seqs_path)\n",
        "\n",
        "  prot1 = seqs[0][1]\n",
        "  prot2 = seqs[1][1]\n",
        "\n",
        "  name1 = seqs[0][0]\n",
        "  name2 = seqs[1][0]\n",
        "\n",
        "  reference_al, query_al, al_score = get_alignments(prot1, prot2, gap_penalty = gap_penalty,\n",
        "                    gap_extension_penalty = gap_extension_penalty ,\n",
        "                                              scoring = scoring , alignment_type = alignment_type,\n",
        "                                              Model = Model , Model_Tokenizer = Model_Tokenizer)\n",
        "\n",
        "  p1_al , aligned_info , p2_al , al_score = get_visualization(reference_al , query_al, al_score , Type = scoring,\n",
        "                                                              Model = Model, Model_Tokenizer = Model_Tokenizer)\n",
        "\n",
        "  full_al_1 = p1_al\n",
        "  full_al_2 = p2_al\n",
        "\n",
        "  FOLDER = saving_add\n",
        "\n",
        "  if not os.path.exists(FOLDER):\n",
        "   os.makedirs(FOLDER)\n",
        "\n",
        "  file_name = FOLDER + seqs_path.split(\"/\")[-1].split(\".\")[-2] + \"_\" + scoring + \"_\" + alignment_type + \"_\"\n",
        "  file_name += str(gap_penalty) + \"_\" + str(gap_extension_penalty) + \"_\"+ \"Alignment\" + \".txt\"\n",
        "  f = open(file_name, \"w\")\n",
        "\n",
        "  f.write(\"Seq 1 \\n\")\n",
        "  f.write(\">\" + name1)\n",
        "  f.write(\"\\n\")\n",
        "  f.write(reference_al.replace(\"-\" , \"\"))\n",
        "  f.write(\"\\n\")\n",
        "  f.write(\"Seq 2 \\n\")\n",
        "  f.write(\">\" + name2)\n",
        "  f.write(\"\\n\")\n",
        "  f.write(query_al.replace(\"-\" , \"\"))\n",
        "  f.write(\"\\n\")\n",
        "  f.write(\"\\n\")\n",
        "  f.write(\"Alignment Type : \" + alignment_type)\n",
        "  f.write(\"\\n\")\n",
        "  f.write(\"\\n\")\n",
        "\n",
        "  f.write(\"Opening Gap Penalty : \" + str(gap_penalty))\n",
        "  f.write(\"\\n\")\n",
        "  f.write(\"Extension Gap Penalty : \" + str(gap_extension_penalty))\n",
        "  f.write(\"\\n\")\n",
        "  f.write(\"Scoring System : \" + scoring)\n",
        "  f.write(\"\\n\")\n",
        "  f.write(\"Score : \"  + str(al_score))\n",
        "\n",
        "  f.write(\"\\n\")\n",
        "  f.write(\"\\n\")\n",
        "\n",
        "  p1_pos = 1\n",
        "  p2_pos = 1\n",
        "  aligned_gaps = \"\"\n",
        "\n",
        "  for j in range(int(len(p1_al) / 60) + 1):\n",
        "    p1_posix = p1_al[j * 60: (j + 1) * 60]\n",
        "    p2_posix = p2_al[j * 60: (j + 1) * 60]\n",
        "    p1_back_str, p2_back_str = length_matcher(str(p1_pos) , str(p2_pos) , place = \"Front\")\n",
        "\n",
        "    for k in range(len(p1_posix)):\n",
        "      if p1_posix[k] != \"-\":\n",
        "        p1_pos += 1\n",
        "      if p2_posix[k] != \"-\":\n",
        "        p2_pos += 1\n",
        "\n",
        "    p1_end_str, p2_end_str = length_matcher(str(p1_pos - 1) , str(p2_pos - 1) , place = \"Back\")\n",
        "    aligned_gaps = \" \" * len(p1_back_str)\n",
        "\n",
        "    f.write(\"Seq 1 : \" + p1_back_str + \" \" + p1_al[j * 60: (j + 1) * 60] + \" \" + p1_end_str)\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"        \"  +  aligned_gaps + \" \" + aligned_info[j * 60: (j + 1) * 60])\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"Seq 2 : \"  + p2_back_str + \" \" + p2_al[j * 60: (j + 1) * 60] + \" \" + p2_end_str)\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "  print(\"Alignment Computation is Done!\")\n",
        "\n",
        "  del Model\n",
        "  del Model_Tokenizer"
      ],
      "metadata": {
        "id": "dyAQgxCFn99V"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def user_guide(MODELS_LIST , ALIGNMENT_TYPES):\n",
        "  print(\"Parameters & Descriptions : \")\n",
        "  print()\n",
        "  print(\"saving_add : the path to the directory for the output\")\n",
        "  print(\"seqs : the path of the directory for the FASTA file with two protein sequences\")\n",
        "  print(\"scoring_type : the embedding method used to produce the embedding vectors;\"  +\n",
        "        \" allowed values are: \" , end = \"\")\n",
        "  for model_name in MODELS_LIST[:-1] : print(model_name + \", \" , end = \"\")\n",
        "  print(MODELS_LIST[-1])\n",
        "\n",
        "  print(\"alignment_type: Global-regular or Global-end-gap-free\")\n",
        "  print(\"gap_penalty = -1 (default); Recommended Values: -4, -3, -2, -1.5, -1, -0.5\")\n",
        "  print(\"gap_expension_penalty = -0.2 (default); Recommended Values: -1, -0.8, -0.5, -0.3, -0.2, -0.1\")"
      ],
      "metadata": {
        "id": "OaiQRMPjkWbg"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tests"
      ],
      "metadata": {
        "id": "AVRUmBYkG4M3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODELS_LIST = [\"ProtT5\" , \"ESM2\" , \"ProtBert\" , \"ProtAlbert\" , \"ESM1b\" ,\"ProtXLNet\"]\n",
        "ALIGNMENT_TYPES = [\"Global-regular\" , \"Global-end-gap-free\"]\n",
        "\n",
        "user_guide(MODELS_LIST , ALIGNMENT_TYPES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Tyat_ydz5f4",
        "outputId": "ed456579-aa2c-4eb8-9ae4-af21feb9f0bb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters & Descriptions : \n",
            "\n",
            "saving_add : the path to the directory for the output\n",
            "seqs : the path of the directory for the FASTA file with two protein sequences\n",
            "scoring_type : the embedding method used to produce the embedding vectors; allowed values are: ProtT5, ESM2, ProtBert, ProtAlbert, ESM1b, ProtXLNet\n",
            "alignment_type: Global-regular or Global-end-gap-free\n",
            "gap_penalty = -1 (default); Recommended Values: -4, -3, -2, -1.5, -1, -0.5\n",
            "gap_expension_penalty = -0.2 (default); Recommended Values: -1, -0.8, -0.5, -0.3, -0.2, -0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saving_add =  \"/content/\"\n",
        "seqs_path = \"Test1.fasta\"\n",
        "scoring = MODELS_LIST[0] #ProtT5\n",
        "alignment_type = ALIGNMENT_TYPES[0] #Global-regular\n",
        "gap_penalty = -1\n",
        "gap_extension_penalty = -0.2\n",
        "\n",
        "alignment_file_TXT(saving_add = saving_add , seqs_path = seqs_path, scoring = scoring, alignment_type = alignment_type,\n",
        "                      gap_penalty = gap_penalty, gap_extension_penalty = gap_extension_penalty)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266,
          "referenced_widgets": [
            "030dcb1c86ad4d6b972655420829dda8",
            "c06dfde833294a90b06254a3ec071081",
            "eb60181f1a2148a081c018588e370553",
            "2c5da0ea00e842d798c16193a03e8e29",
            "c19065496da34801ae54401628fdbb20",
            "c5dddb9466ea4408ab85df1165ae310a",
            "84324e0bd217405d9e5fdbe8931de644",
            "ec03d105b1ee47f4a7890283493dedb4",
            "deb58c8345ce474a8355b88577ef56e2",
            "d3716cec13b14be996cd5d5fdce7ebe5",
            "a19cfd81ce7b4322a0252212a6de81f7",
            "b80106bb81fc46d38a7e3e1bc6abe948",
            "910d2c64ce9c44f49b2c27b8631ecaea",
            "d88e2799bf854307b156d2b162aca28f",
            "88da7d67d40c414cbf2a0be2cded1f01",
            "6293f6995f144171b440c91f124e2469",
            "acb1e97c899e43da8298ca7b1b477a73",
            "391fbb9e12334738996ebbaeedb8b51a",
            "7c54638b4bc04f02979b19f615741f4e",
            "e89faf88d3d5494c89727a761b20cf77",
            "885e26e1d5b149949cfe29b1b79f3840",
            "1e709635f14942f7b25d0a11c87dad18",
            "6a5d0d2ebfb4451e91b4f012252450be",
            "d356a93a4efc4e438b229cced1c6863a",
            "dfdda42132f345eda591cabeacc5afd2",
            "c477a3ae837e4516a6b95eb7a8d3b214",
            "55eeddd544fe4255b72f2f1d46aee3a4",
            "2194887ff49149a882dd6be7e29732cb",
            "abd3dcb2c29a47879102260ad3d436b8",
            "95003a4da9574d5da6d1a3f305d83e95",
            "693c8cd2bd2b414fbfca4819cad1fec7",
            "4a777ac5eb5643938745185db7a14d1d",
            "cafdb50cc01a42b59724342158dc1691",
            "0b8405bf1f144c5b9162aa0726fa4942",
            "8d99aa44481a417da415e5cf1753f5d4",
            "b6abff731ac04acb972492fdd4c67ae5",
            "8cbdf886364c4d3d8c781e72e7d380bd",
            "c607f30cfcd9489094373124d53c39b1",
            "62a3ca2abef6459094ad4820787a72e7",
            "88e36e793be64c8e8d6bf73c8c785f99",
            "9de99d36bc0647c88a669064a3a346f3",
            "ab979e99863d411ea734e366162cec2c",
            "806a42bd9bf84cc7ab5926d990477dbb",
            "939734513cec47d994ad090e5429acf2",
            "3212530134a44679930bb499ee46c8ab",
            "ca6eaed1aa01464a8308375f54aa7123",
            "4a554044cf73487b9e88b09775be414d",
            "98e9748a82864b0fad9ace2d983f3e54",
            "6506e1e2bcb64c7ab5f63ba38b0a2cf6",
            "cf22046be6fb4f79b95bb4f2baf860f7",
            "741a12ac210943a0b6014b317ec1df08",
            "4b6776b6290746d3a57b5a9aa719429d",
            "c355869949c7499c85564ed28961e9b1",
            "648376aeaba9430a8d011ac522f0f3a1",
            "b5981fbc93dd47f1a99897e8e3e61533"
          ]
        },
        "id": "glng92tRG5ZZ",
        "outputId": "a6c2f3a9-76f4-416b-8e92-1aa42957e8e2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ProtT5 Initialize : \n",
            "Loading: Rostlab/prot_t5_xl_half_uniref50-enc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/656 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "030dcb1c86ad4d6b972655420829dda8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/2.42G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b80106bb81fc46d38a7e3e1bc6abe948"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/238k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a5d0d2ebfb4451e91b4f012252450be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b8405bf1f144c5b9162aa0726fa4942"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3212530134a44679930bb499ee46c8ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alignment Computation is Done!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Dq9u86RyHKk_",
        "8LCdgRFBFWW6",
        "8ctdjBhTGi9z",
        "wiNZQ2SQJM54",
        "9IMkkTPWsaF0"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "030dcb1c86ad4d6b972655420829dda8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c06dfde833294a90b06254a3ec071081",
              "IPY_MODEL_eb60181f1a2148a081c018588e370553",
              "IPY_MODEL_2c5da0ea00e842d798c16193a03e8e29"
            ],
            "layout": "IPY_MODEL_c19065496da34801ae54401628fdbb20"
          }
        },
        "c06dfde833294a90b06254a3ec071081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5dddb9466ea4408ab85df1165ae310a",
            "placeholder": "​",
            "style": "IPY_MODEL_84324e0bd217405d9e5fdbe8931de644",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "eb60181f1a2148a081c018588e370553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec03d105b1ee47f4a7890283493dedb4",
            "max": 656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_deb58c8345ce474a8355b88577ef56e2",
            "value": 656
          }
        },
        "2c5da0ea00e842d798c16193a03e8e29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3716cec13b14be996cd5d5fdce7ebe5",
            "placeholder": "​",
            "style": "IPY_MODEL_a19cfd81ce7b4322a0252212a6de81f7",
            "value": " 656/656 [00:00&lt;00:00, 31.0kB/s]"
          }
        },
        "c19065496da34801ae54401628fdbb20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5dddb9466ea4408ab85df1165ae310a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84324e0bd217405d9e5fdbe8931de644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec03d105b1ee47f4a7890283493dedb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deb58c8345ce474a8355b88577ef56e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3716cec13b14be996cd5d5fdce7ebe5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a19cfd81ce7b4322a0252212a6de81f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b80106bb81fc46d38a7e3e1bc6abe948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_910d2c64ce9c44f49b2c27b8631ecaea",
              "IPY_MODEL_d88e2799bf854307b156d2b162aca28f",
              "IPY_MODEL_88da7d67d40c414cbf2a0be2cded1f01"
            ],
            "layout": "IPY_MODEL_6293f6995f144171b440c91f124e2469"
          }
        },
        "910d2c64ce9c44f49b2c27b8631ecaea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acb1e97c899e43da8298ca7b1b477a73",
            "placeholder": "​",
            "style": "IPY_MODEL_391fbb9e12334738996ebbaeedb8b51a",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "d88e2799bf854307b156d2b162aca28f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c54638b4bc04f02979b19f615741f4e",
            "max": 2416373051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e89faf88d3d5494c89727a761b20cf77",
            "value": 2416373051
          }
        },
        "88da7d67d40c414cbf2a0be2cded1f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_885e26e1d5b149949cfe29b1b79f3840",
            "placeholder": "​",
            "style": "IPY_MODEL_1e709635f14942f7b25d0a11c87dad18",
            "value": " 2.42G/2.42G [00:24&lt;00:00, 74.9MB/s]"
          }
        },
        "6293f6995f144171b440c91f124e2469": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acb1e97c899e43da8298ca7b1b477a73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "391fbb9e12334738996ebbaeedb8b51a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c54638b4bc04f02979b19f615741f4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e89faf88d3d5494c89727a761b20cf77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "885e26e1d5b149949cfe29b1b79f3840": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e709635f14942f7b25d0a11c87dad18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a5d0d2ebfb4451e91b4f012252450be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d356a93a4efc4e438b229cced1c6863a",
              "IPY_MODEL_dfdda42132f345eda591cabeacc5afd2",
              "IPY_MODEL_c477a3ae837e4516a6b95eb7a8d3b214"
            ],
            "layout": "IPY_MODEL_55eeddd544fe4255b72f2f1d46aee3a4"
          }
        },
        "d356a93a4efc4e438b229cced1c6863a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2194887ff49149a882dd6be7e29732cb",
            "placeholder": "​",
            "style": "IPY_MODEL_abd3dcb2c29a47879102260ad3d436b8",
            "value": "Downloading (…)ve/main/spiece.model: 100%"
          }
        },
        "dfdda42132f345eda591cabeacc5afd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95003a4da9574d5da6d1a3f305d83e95",
            "max": 237990,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_693c8cd2bd2b414fbfca4819cad1fec7",
            "value": 237990
          }
        },
        "c477a3ae837e4516a6b95eb7a8d3b214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a777ac5eb5643938745185db7a14d1d",
            "placeholder": "​",
            "style": "IPY_MODEL_cafdb50cc01a42b59724342158dc1691",
            "value": " 238k/238k [00:00&lt;00:00, 4.18MB/s]"
          }
        },
        "55eeddd544fe4255b72f2f1d46aee3a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2194887ff49149a882dd6be7e29732cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abd3dcb2c29a47879102260ad3d436b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95003a4da9574d5da6d1a3f305d83e95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "693c8cd2bd2b414fbfca4819cad1fec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a777ac5eb5643938745185db7a14d1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cafdb50cc01a42b59724342158dc1691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b8405bf1f144c5b9162aa0726fa4942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d99aa44481a417da415e5cf1753f5d4",
              "IPY_MODEL_b6abff731ac04acb972492fdd4c67ae5",
              "IPY_MODEL_8cbdf886364c4d3d8c781e72e7d380bd"
            ],
            "layout": "IPY_MODEL_c607f30cfcd9489094373124d53c39b1"
          }
        },
        "8d99aa44481a417da415e5cf1753f5d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62a3ca2abef6459094ad4820787a72e7",
            "placeholder": "​",
            "style": "IPY_MODEL_88e36e793be64c8e8d6bf73c8c785f99",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "b6abff731ac04acb972492fdd4c67ae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9de99d36bc0647c88a669064a3a346f3",
            "max": 1787,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab979e99863d411ea734e366162cec2c",
            "value": 1787
          }
        },
        "8cbdf886364c4d3d8c781e72e7d380bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_806a42bd9bf84cc7ab5926d990477dbb",
            "placeholder": "​",
            "style": "IPY_MODEL_939734513cec47d994ad090e5429acf2",
            "value": " 1.79k/1.79k [00:00&lt;00:00, 111kB/s]"
          }
        },
        "c607f30cfcd9489094373124d53c39b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62a3ca2abef6459094ad4820787a72e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88e36e793be64c8e8d6bf73c8c785f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9de99d36bc0647c88a669064a3a346f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab979e99863d411ea734e366162cec2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "806a42bd9bf84cc7ab5926d990477dbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "939734513cec47d994ad090e5429acf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3212530134a44679930bb499ee46c8ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca6eaed1aa01464a8308375f54aa7123",
              "IPY_MODEL_4a554044cf73487b9e88b09775be414d",
              "IPY_MODEL_98e9748a82864b0fad9ace2d983f3e54"
            ],
            "layout": "IPY_MODEL_6506e1e2bcb64c7ab5f63ba38b0a2cf6"
          }
        },
        "ca6eaed1aa01464a8308375f54aa7123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf22046be6fb4f79b95bb4f2baf860f7",
            "placeholder": "​",
            "style": "IPY_MODEL_741a12ac210943a0b6014b317ec1df08",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "4a554044cf73487b9e88b09775be414d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b6776b6290746d3a57b5a9aa719429d",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c355869949c7499c85564ed28961e9b1",
            "value": 25
          }
        },
        "98e9748a82864b0fad9ace2d983f3e54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_648376aeaba9430a8d011ac522f0f3a1",
            "placeholder": "​",
            "style": "IPY_MODEL_b5981fbc93dd47f1a99897e8e3e61533",
            "value": " 25.0/25.0 [00:00&lt;00:00, 1.54kB/s]"
          }
        },
        "6506e1e2bcb64c7ab5f63ba38b0a2cf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf22046be6fb4f79b95bb4f2baf860f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "741a12ac210943a0b6014b317ec1df08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b6776b6290746d3a57b5a9aa719429d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c355869949c7499c85564ed28961e9b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "648376aeaba9430a8d011ac522f0f3a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5981fbc93dd47f1a99897e8e3e61533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}